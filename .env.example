# Homunculus Environment Configuration
# Copy this file to .env and fill in the values.
# NEVER commit .env to version control.

# Gateway authentication (bcrypt hash of your auth token)
# Generated by scripts/setup.sh on first run
GATEWAY_AUTH_TOKEN_HASH=

# Anthropic API key for escalation model
ANTHROPIC_API_KEY=

# Escalation to remote models (Claude). Set to false for local-only mode.
# When disabled, all tasks route to the local model (Ollama) and Claude is
# never called â€” ideal for experimenting with local/custom models.
# ESCALATION_ENABLED=false

# Ollama base URL (overrides models.local.base_url in config)
# For host Ollama (default when running outside Docker):
# OLLAMA_BASE_URL=http://localhost:11434
# When using Ollama as a Docker service (see docs/QUICK_SETUP.md):
# OLLAMA_BASE_URL=http://ollama:11434

# Log level: debug, info, warn, error, fatal
LOG_LEVEL=info

# Telegram bot token (from @BotFather)
TELEGRAM_BOT_TOKEN=

# Ruby YJIT (enabled by default in container)
# RUBY_YJIT_ENABLE=1
